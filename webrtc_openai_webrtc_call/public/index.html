<!doctype html>
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>AI-mediated WebRTC chat (debug-2)</title>

<style>
  body  { font-family:sans-serif; text-align:center; margin-top:2em; }
  input,button{ font-size:1.05em; }
  button{ margin-left:.3em; }
  pre   { text-align:left; max-width:90%; margin:1em auto;
          background:#f3f3f3; padding:.7em; }
</style>

<h2>WebRTC chat – model’s voice only for the remote peer</h2>
<p>
  Room:
  <input id="roomInput" placeholder="choose-a-room">
  <button id="joinBtn" disabled>Join</button>
</p>

<audio id="remoteAudio" autoplay playsinline></audio>
<pre id="log"></pre>

<script>
/* ---------- tiny logger ---------- */
const logEl = document.getElementById('log');
function log(...a){
  const txt = a.map(v=>typeof v==='string'?v:JSON.stringify(v)).join(' ');
  console.log('[DBG]', ...a);
  logEl.textContent += txt + '\n';
}

/* ---------- UI ---------- */
const roomInput   = document.getElementById('roomInput');
const joinBtn     = document.getElementById('joinBtn');
const remoteAudio = document.getElementById('remoteAudio');

roomInput.addEventListener('input', () =>
  joinBtn.disabled = roomInput.value.trim() === ''
);
joinBtn.addEventListener('click', joinRoom);

/* ---------- globals ---------- */
let pcOai, pcChat, ws;               // OpenAI-PC, chat-PC, signalling WS
let statsTimer;

/* helper: wait until pc.iceGatheringState === 'complete' */
function waitIceComplete(pc){
  return new Promise(res=>{
    if(pc.iceGatheringState==='complete') return res();
    pc.addEventListener('icegatheringstatechange', function h(){
      if(pc.iceGatheringState==='complete'){ pc.removeEventListener('icegatheringstatechange',h); res(); }
    });
  });
}

/* ---------- OpenAI connection ---------- */
async function connectToOpenAI(micTrack) {
  log('Fetching ephemeral OpenAI token …');
  const { client_secret } = await (await fetch('/session')).json();
  const EPHEMERAL = client_secret.value;

  pcOai = new RTCPeerConnection({
    iceServers:[{urls:'stun:stun.l.google.com:19302'}]
  });
  pcOai.addTrack(micTrack);
  log('pcOai created, micTrack added', micTrack.id);

  /* optional data-channel for transcripts / events */
  const dc = pcOai.createDataChannel('oai-events');
  dc.onopen    = ()=>log('oai-events DC open');
  dc.onmessage = ev =>{
    try{ log('oai-event', JSON.parse(ev.data)); }
    catch{ log('oai-raw', ev.data); }
  };

  pcOai.ontrack = ({ streams }) => {
    const modelStream = streams[0];
    log('<< received modelStream from OpenAI', modelStream.id);

    /* remote → local track via AudioContext */
    const ctx  = new (window.AudioContext||window.webkitAudioContext)();
    const src  = ctx.createMediaStreamSource(modelStream);
    const dest = ctx.createMediaStreamDestination();
    src.connect(dest);
    const sendTrack = dest.stream.getAudioTracks()[0];
    log('new local sendTrack', sendTrack.id);

    if (!pcChat){
      buildChatPC(sendTrack);
      if (ws?.readyState === WebSocket.OPEN) negotiateChat();
    } else {
      const sender = pcChat.getSenders()
                           .find(s=>s.track && s.track.kind==='audio');
      if (sender){ sender.replaceTrack(sendTrack); log('replaced track'); }
      else       { pcChat.addTrack(sendTrack);     log('addTrack');       }
    }
  };

  /* SDP with OpenAI – need ICE candidates first! */
  log('Creating SDP offer for OpenAI …');
  await pcOai.setLocalDescription(await pcOai.createOffer());
  await waitIceComplete(pcOai);
  log('ICE gathering done, candidates in SDP');

  const offerSdp = pcOai.localDescription.sdp;
  const ansTxt = await fetch(
    'https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2025-06-03',
    { method:'POST',
      headers:{ Authorization:`Bearer ${EPHEMERAL}`,
                'Content-Type':'application/sdp' },
      body:offerSdp }
  ).then(r=>r.text());
  log('Received SDP answer from OpenAI (len', ansTxt.length,')');

  await pcOai.setRemoteDescription({ type:'answer', sdp:ansTxt });
  log('pcOai setRemoteDescription → connected? wait for “<< modelStream …”');
}

/* ---------- browser ↔ browser ---------- */
function buildChatPC(firstTrack){
  pcChat = new RTCPeerConnection({
    iceServers:[{urls:'stun:stun.l.google.com:19302'}]
  });
  if(firstTrack){ pcChat.addTrack(firstTrack); log('pcChat addTrack', firstTrack.id); }

  pcChat.onicecandidate = ({candidate})=>{
    if (candidate && ws?.readyState===WebSocket.OPEN)
      ws.send(JSON.stringify({ice:candidate}));
  };

  pcChat.ontrack = ({ track, streams })=>{
    log('>> pcChat ontrack', track.id, 'kind', track.kind);
    remoteAudio.srcObject = streams[0];

    remoteAudio.play()
      .then(()=>log('remoteAudio.play() succeeded'))
      .catch(e =>log('remoteAudio.play() rejected', e.name, e.message));
  };

  /* periodic RTP byte counters */
  clearInterval(statsTimer);
  statsTimer = setInterval(async ()=>{
    if(!pcChat) return;
    const stats = await pcChat.getStats();
    let inB=0,outB=0;
    stats.forEach(r=>{
      if (r.type==='inbound-rtp'  && r.kind==='audio') inB  += r.bytesReceived;
      if (r.type==='outbound-rtp' && r.kind==='audio') outB += r.bytesSent;
    });
    log('RTP bytes  ▲',outB,'  ▼',inB);
  },3000);
}

async function negotiateChat(){
  if(!pcChat) return;
  if(location.hash!=='#callee'){
    const offer = await pcChat.createOffer();
    await pcChat.setLocalDescription(offer);
    ws.send(JSON.stringify({offer}));
    log('Sent chat SDP offer');
  }
}

/* ---------- entry point ---------- */
async function joinRoom(){
  joinBtn.disabled = true;
  log('joinRoom pressed');

  /* mic */
  let localStream;
  try{
    localStream = await navigator.mediaDevices.getUserMedia({
      audio:{ echoCancellation:true, noiseSuppression:true }
    });
  }catch(e){
    alert('Need microphone access'); joinBtn.disabled=false; return;
  }
  const micTrack = localStream.getAudioTracks()[0];
  log('got mic track', micTrack.label);

  await connectToOpenAI(micTrack);

  /* signalling WS */
  const proto = location.protocol==='https:'?'wss':'ws';
  ws = new WebSocket(`${proto}://${location.host}/ws`);
  ws.onopen = ()=>{
    ws.send(JSON.stringify({join:roomInput.value.trim()}));
    negotiateChat();
    log('WS open, joined room');
  };

  ws.onmessage = async ev=>{
    const text = typeof ev.data==='string' ? ev.data : await ev.data.text();
    let msg; try{msg=JSON.parse(text);}catch{return;}

    if(msg.offer){
      log('Received chat offer');
      await pcChat.setRemoteDescription(msg.offer);
      const answer = await pcChat.createAnswer();
      await pcChat.setLocalDescription(answer);
      ws.send(JSON.stringify({answer}));
      location.hash='#callee';
      log('Sent chat answer');
    }else if(msg.answer){
      log('Received chat answer');
      await pcChat.setRemoteDescription(msg.answer);
    }else if(msg.ice){
      try{ await pcChat.addIceCandidate(msg.ice); }
      catch{}
    }
  };
}
</script>